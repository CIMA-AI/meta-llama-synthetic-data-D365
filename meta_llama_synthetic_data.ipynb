{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cuP6tsK2HIeJg76c0uLKajYY",
      "metadata": {
        "id": "cuP6tsK2HIeJg76c0uLKajYY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install -q gcsfs pyyaml openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iAhvAXc7wqf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iAhvAXc7wqf0",
        "outputId": "bbb853d8-cdb4-4570-9220-600d51e241d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/meta-llama/synthetic-data-kit.git@main\n",
            "  Cloning https://github.com/meta-llama/synthetic-data-kit.git (to revision main) to /tmp/pip-req-build-nf28cg3m\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/meta-llama/synthetic-data-kit.git /tmp/pip-req-build-nf28cg3m\n",
            "  Resolved https://github.com/meta-llama/synthetic-data-kit.git to commit 2e68548299df4383f1c5b34f3a9883e8840f9ac6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bootstrap-flask>=2.2.0 (from synthetic-data-kit==0.0.4b2)\n",
            "  Downloading bootstrap_flask-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (2.14.4)\n",
            "Collecting flask-wtf>=1.0.0 (from synthetic-data-kit==0.0.4b2)\n",
            "  Downloading flask_wtf-1.2.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: flask>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (3.1.1)\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (1.91.0)\n",
            "Collecting pdfminer-six>=20221105 (from synthetic-data-kit==0.0.4b2)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pydantic>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (2.11.7)\n",
            "Collecting python-docx>=0.8.11 (from synthetic-data-kit==0.0.4b2)\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx>=0.6.21 (from synthetic-data-kit==0.0.4b2)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pytube>=15.0.0 (from synthetic-data-kit==0.0.4b2)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (2.32.3)\n",
            "Requirement already satisfied: rich>=13.4.2 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (13.9.4)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (0.16.0)\n",
            "Collecting WTForms (from bootstrap-flask>=2.2.0->synthetic-data-kit==0.0.4b2)\n",
            "  Downloading wtforms-3.2.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (24.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (3.1.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->synthetic-data-kit==0.0.4b2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->synthetic-data-kit==0.0.4b2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->synthetic-data-kit==0.0.4b2) (0.4.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx>=0.8.11->synthetic-data-kit==0.0.4b2) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx>=0.6.21->synthetic-data-kit==0.0.4b2) (11.2.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx>=0.6.21->synthetic-data-kit==0.0.4b2)\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->synthetic-data-kit==0.0.4b2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->synthetic-data-kit==0.0.4b2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->synthetic-data-kit==0.0.4b2) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.4.2->synthetic-data-kit==0.0.4b2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.4.2->synthetic-data-kit==0.0.4b2) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->synthetic-data-kit==0.0.4b2) (1.5.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (1.17.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (6.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.20.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->synthetic-data-kit==0.0.4b2) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->synthetic-data-kit==0.0.4b2) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.1.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->synthetic-data-kit==0.0.4b2) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2025.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.17.0)\n",
            "Downloading bootstrap_flask-2.5.0-py3-none-any.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_wtf-1.2.2-py3-none-any.whl (12 kB)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wtforms-3.2.1-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: synthetic-data-kit\n",
            "  Building wheel for synthetic-data-kit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for synthetic-data-kit: filename=synthetic_data_kit-0.0.4b2-py3-none-any.whl size=70186 sha256=900ef0657127af4ce077da61c9d08c60caa057cfdcac239901511c7985de1166\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p4zzidgc/wheels/88/84/c2/11b1c6477a5aea3412af7e0e90e9d77c4ecfcd96f2927b81af\n",
            "Successfully built synthetic-data-kit\n",
            "Installing collected packages: XlsxWriter, WTForms, pytube, python-docx, python-pptx, pdfminer-six, flask-wtf, bootstrap-flask, synthetic-data-kit\n",
            "Successfully installed WTForms-3.2.1 XlsxWriter-3.2.5 bootstrap-flask-2.5.0 flask-wtf-1.2.2 pdfminer-six-20250506 python-docx-1.2.0 python-pptx-1.0.2 pytube-15.0.0 synthetic-data-kit-0.0.4b2\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/meta-llama/synthetic-data-kit.git@main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rrbnrjGCwucN",
      "metadata": {
        "id": "rrbnrjGCwucN"
      },
      "outputs": [],
      "source": [
        "# GCP project credentials\n",
        "import vertexai, os\n",
        "PROJECT_ID   = \"poc-uni-t-plus\"\n",
        "LOCATION     = \"us-central1\"\n",
        "BUCKET       = \"qa-benchmark\"\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RfkzGpFmw7uT",
      "metadata": {
        "id": "RfkzGpFmw7uT"
      },
      "outputs": [],
      "source": [
        "# Create folders here\n",
        "!mkdir -p data/{pdf,html,youtube,docx,ppt,txt,output,generated,cleaned,final,result} configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tHb8_jXfw_CT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tHb8_jXfw_CT",
        "outputId": "9540c250-dfa3-4700-c50c-e262db4754d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://qa-benchmark/raw/GUI-A20-010 Job Aid – How to Upload and Reference a Document in SharePoint (corporate documents)_EN_V1.0.pdf...\n",
            "Copying gs://qa-benchmark/raw/GUI-A20-100 Job Aid - SharePoint and Contractual Documents_EN_V1.1.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \r/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-B31-100 Job Aid - Opening a Sales Project_EN_V1.1.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-A61-100 Job Aid - Project Risk Analysis_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-B31-110 Job Aid - Opening a Client Project in GP for Project Accounting_EN_V1.2.pdf...\n",
            "Copying gs://qa-benchmark/raw/GUI-C20-001 Job Aid - Create a Custom Dashboard_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \r/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-010 Job Aid - Quick Creation of a Client Account_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C30-220 Job Aid - Project Amendment Process_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-002 Job Aid - Create Custom Views_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-200 Job Aid - Call Up Opportunity_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C30-220 Job Aid - Project Amendment Process_EN_V1.0 (1).pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-120 Job Aid - Disqualify a Lead_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-210 Job Aid - Opportunity Master Agreement_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-110 Job Aid - Delegate the Entry of the Lead Qualification_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C30-200 Job Aid - Client Project Structure Change Request (SDP - WBS)_EN_V1.1.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C30-100 Job Aid - Using Project Ops and Finding the SharePoint_EN_V1.1.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C30-210 Job Aid - SDP_WBS File Opening and Notification Process_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-100 Job Aid - Potential Leads_EN_V1.0.pdf...\n",
            "/ [0/21 files][    0.0 B/ 23.1 MiB]   0% Done                                   \rCopying gs://qa-benchmark/raw/GUI-C20-015 Job Aid - Create a Child Account_EN_V1.0.pdf...\n",
            "Copying gs://qa-benchmark/raw/GUI-C20-215 Job Aid - Recreate MSA_EN_V1.0.pdf...\n",
            "Copying gs://qa-benchmark/raw/GUI-C31-110 Job Aid - Creation of a Client Project_EN_V1.0.pdf...\n",
            "- [21/21 files][ 23.1 MiB/ 23.1 MiB] 100% Done                                  \n",
            "Operation completed over 21 objects/23.1 MiB.                                    \n"
          ]
        }
      ],
      "source": [
        "## transfer data from gcs to data folder here\n",
        "!gsutil -m cp gs://qa-benchmark/raw/*.pdf data/pdf/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oPOkPNx0xAdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oPOkPNx0xAdd",
        "outputId": "c5676df6-65ff-45e9-94b4-517693e85903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "llm:\n",
            "  provider: \"api-endpoint\"          # <- tells the kit we’re using HTTPS, not vLLM\n",
            "\n",
            "api-endpoint:\n",
            "  api_base: \"https://api.openai.com/v1\"   # OpenAI REST root\n",
            "  api_key: \"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\"\n",
            "  model:    \"gpt-4o-mini\"\n",
            "  max_retries: 3\n",
            "  retry_delay: 1.0\n",
            "\n",
            "generation:\n",
            "  temperature: 0.5   # Higher = more creative, lower = more deterministic\n",
            "  top_p: 0.95        # Nucleus sampling parameter\n",
            "  chunk_size: 500   # Size of text chunks for processing\n",
            "  overlap: 50       # Overlap between chunks to maintain context\n",
            "  max_tokens: 10000   # Maximum tokens in LLM responses\n",
            "  num_pairs: 30      # Default number of QA pairs to generate\n",
            "  num_cot_examples: 20  # Default number of Chain of Thought examples to generate\n",
            "  num_cot_enhance_examples: null  # Maximum number of conversations to enhance (null = enhance all)\n",
            "  batch_size: 32     # Number of requests to batch together (for create)\n",
            "\n",
            "# Content curation parameters\n",
            "curate:\n",
            "  threshold: 7.0     # Default quality threshold (1-10)\n",
            "  batch_size: 32     # Number of items per batch for rating\n",
            "  inference_batch: 32 # Number of batches to process at once with VLLM\n",
            "  temperature: 0.1   # Temperature for rating (lower = more consistent)\n",
            "\n",
            "# Format conversion parameters\n",
            "format:\n",
            "  default: \"jsonl\"   # Default output format\n",
            "  include_metadata: true  # Include metadata in output files\n",
            "  pretty_json: true  # Use indentation in JSON output\n",
            "\n",
            "# Prompts for different tasks\n",
            "prompts:\n",
            "  # Summary generation prompt\n",
            "  summary: |\n",
            "    Summarize the provided document in 3–5 sentences. Your summary should clearly identify the main topic, highlight the most important concepts or procedures, and capture any essential technical details or requirements. Avoid including minor details or tangential information. Write your summary in clear, concise language, ensuring that it provides an accurate overview for someone unfamiliar with the original document\n",
            "\n",
            "  # QA pair generation prompt\n",
            "  qa_generation: |\n",
            "    You are required to generate {num_pairs} complex and meaningful question-answer pairs from the provided document content to build a validation dataset. Follow these guidelines carefully: Please provide complete answers to the questions; do not give incomplete or partial answers. Each answer must provide all necessary details explicitly. Base your question on the technical aspects of the documents. Formulate realistic and meaningful questions that anticipate genuine inquiries a user might have regarding the technical procedures, rules, or detailed instructions described in the document. Avoid overly simplistic, trivial, or obvious questions. Ensure all questions directly address the technical aspects or detailed procedural content within the document. Do not create administrative or ownership-related\n",
            "\n",
            "    Rules:\n",
            "    1. Questions must be about important facts in the text\n",
            "    2. Answers must be directly supported by the text\n",
            "    3. Return JSON format only:\n",
            "\n",
            "    [\n",
            "      {{\n",
            "        \"question\": \"Question 1?\",\n",
            "        \"answer\": \"Answer 1.\"\n",
            "      }},\n",
            "      {{\n",
            "        \"question\": \"Question 2?\",\n",
            "        \"answer\": \"Answer 2.\"\n",
            "      }}\n",
            "    ]\n",
            "\n",
            "    Text:\n",
            "    {text}\n",
            "\n",
            "  qa_rating: |\n",
            "    Rate each question-answer pair on a scale from 1-10, based on:\n",
            "    - Accuracy (0-3): factual correctness\n",
            "    - Relevance (0-2): relevance to content\n",
            "    - Clarity (0-2): clear language\n",
            "    - Usefulness (0-3): value for model learning\n",
            "\n",
            "    YOU MUST RETURN A VALID JSON OBJECT OR ARRAY WITH THIS EXACT SCHEMA:\n",
            "    {{\n",
            "      \"question\": \"Exact question text\",\n",
            "      \"answer\": \"Exact answer text\",\n",
            "      \"rating\": 8\n",
            "    }}\n",
            "\n",
            "    OR FOR MULTIPLE PAIRS:\n",
            "    [\n",
            "      {{\"question\": \"Q1\", \"answer\": \"A1\", \"rating\": 8}},\n",
            "      {{\"question\": \"Q2\", \"answer\": \"A2\", \"rating\": 9}}\n",
            "    ]\n",
            "\n",
            "  # Chain of Thought generation prompt\n",
            "  cot_generation: |\n",
            "    Create {num_examples} complex reasoning examples from this text that demonstrate chain-of-thought thinking.\n",
            "\n",
            "    Each example should have:\n",
            "    1. A challenging question that requires step-by-step reasoning\n",
            "    2. Detailed reasoning steps that break down the problem\n",
            "    3. A concise final answer\n",
            "\n",
            "    Return JSON format only:\n",
            "\n",
            "    [\n",
            "      {{\n",
            "        \"question\": \"Complex question about the text?\",\n",
            "        \"reasoning\": \"Step 1: First, I need to consider...\n",
            "Step 2: Then, I analyze...\n",
            "Step 3: Finally, I can conclude...\",\n",
            "        \"answer\": \"Final answer based on the reasoning.\"\n",
            "      }},\n",
            "      {{\n",
            "        \"question\": \"Another complex question?\",\n",
            "        \"reasoning\": \"Step 1: First, I'll analyze...\n",
            "Step 2: Next, I need to determine...\n",
            "Step 3: Based on this analysis...\",\n",
            "        \"answer\": \"Final answer drawn from the reasoning.\"\n",
            "      }}\n",
            "    ]\n",
            "\n",
            "    Text:\n",
            "    {text}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Config file\n",
        "import textwrap, yaml, pathlib, json, os\n",
        "\n",
        "cfg = textwrap.dedent(\"\"\"\n",
        "llm:\n",
        "  provider: \"api-endpoint\"          # <- tells the kit we’re using HTTPS, not vLLM\n",
        "\n",
        "api-endpoint:\n",
        "  api_base: \"https://api.openai.com/v1\"   # OpenAI REST root\n",
        "  api_key: \"\"\n",
        "  model:    \"gpt-4o-mini\"\n",
        "  max_retries: 3\n",
        "  retry_delay: 1.0\n",
        "\n",
        "generation:\n",
        "  temperature: 0.5   # Higher = more creative, lower = more deterministic\n",
        "  top_p: 0.95        # Nucleus sampling parameter\n",
        "  chunk_size: 500   # Size of text chunks for processing\n",
        "  overlap: 50       # Overlap between chunks to maintain context\n",
        "  max_tokens: 10000   # Maximum tokens in LLM responses\n",
        "  num_pairs: 30      # Default number of QA pairs to generate\n",
        "  num_cot_examples: 20  # Default number of Chain of Thought examples to generate\n",
        "  num_cot_enhance_examples: null  # Maximum number of conversations to enhance (null = enhance all)\n",
        "  batch_size: 32     # Number of requests to batch together (for create)\n",
        "\n",
        "# Content curation parameters\n",
        "curate:\n",
        "  threshold: 7.0     # Default quality threshold (1-10)\n",
        "  batch_size: 32     # Number of items per batch for rating\n",
        "  inference_batch: 32 # Number of batches to process at once with VLLM\n",
        "  temperature: 0.1   # Temperature for rating (lower = more consistent)\n",
        "\n",
        "# Format conversion parameters\n",
        "format:\n",
        "  default: \"jsonl\"   # Default output format\n",
        "  include_metadata: true  # Include metadata in output files\n",
        "  pretty_json: true  # Use indentation in JSON output\n",
        "\n",
        "# Prompts for different tasks\n",
        "prompts:\n",
        "  # Summary generation prompt\n",
        "  summary: |\n",
        "    Summarize the provided document in 3–5 sentences. Your summary should clearly identify the main topic, highlight the most important concepts or procedures, and capture any essential technical details or requirements. Avoid including minor details or tangential information. Write your summary in clear, concise language, ensuring that it provides an accurate overview for someone unfamiliar with the original document\n",
        "\n",
        "  # QA pair generation prompt\n",
        "  qa_generation: |\n",
        "    You are required to generate {num_pairs} complex and meaningful question-answer pairs from the provided document content to build a validation dataset. Follow these guidelines carefully: Please provide complete answers to the questions; do not give incomplete or partial answers. Each answer must provide all necessary details explicitly. Base your question on the technical aspects of the documents. Formulate realistic and meaningful questions that anticipate genuine inquiries a user might have regarding the technical procedures, rules, or detailed instructions described in the document. Avoid overly simplistic, trivial, or obvious questions. Ensure all questions directly address the technical aspects or detailed procedural content within the document. Do not create administrative or ownership-related\n",
        "\n",
        "    Rules:\n",
        "    1. Questions must be about important facts in the text\n",
        "    2. Answers must be directly supported by the text\n",
        "    3. Return JSON format only:\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"question\": \"Question 1?\",\n",
        "        \"answer\": \"Answer 1.\"\n",
        "      }},\n",
        "      {{\n",
        "        \"question\": \"Question 2?\",\n",
        "        \"answer\": \"Answer 2.\"\n",
        "      }}\n",
        "    ]\n",
        "\n",
        "    Text:\n",
        "    {text}\n",
        "\n",
        "  qa_rating: |\n",
        "    Rate each question-answer pair on a scale from 1-10, based on:\n",
        "    - Accuracy (0-3): factual correctness\n",
        "    - Relevance (0-2): relevance to content\n",
        "    - Clarity (0-2): clear language\n",
        "    - Usefulness (0-3): value for model learning\n",
        "\n",
        "    YOU MUST RETURN A VALID JSON OBJECT OR ARRAY WITH THIS EXACT SCHEMA:\n",
        "    {{\n",
        "      \"question\": \"Exact question text\",\n",
        "      \"answer\": \"Exact answer text\",\n",
        "      \"rating\": 8\n",
        "    }}\n",
        "\n",
        "    OR FOR MULTIPLE PAIRS:\n",
        "    [\n",
        "      {{\"question\": \"Q1\", \"answer\": \"A1\", \"rating\": 8}},\n",
        "      {{\"question\": \"Q2\", \"answer\": \"A2\", \"rating\": 9}}\n",
        "    ]\n",
        "\n",
        "  # Chain of Thought generation prompt\n",
        "  cot_generation: |\n",
        "    Create {num_examples} complex reasoning examples from this text that demonstrate chain-of-thought thinking.\n",
        "\n",
        "    Each example should have:\n",
        "    1. A challenging question that requires step-by-step reasoning\n",
        "    2. Detailed reasoning steps that break down the problem\n",
        "    3. A concise final answer\n",
        "\n",
        "    Return JSON format only:\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"question\": \"Complex question about the text?\",\n",
        "        \"reasoning\": \"Step 1: First, I need to consider...\\nStep 2: Then, I analyze...\\nStep 3: Finally, I can conclude...\",\n",
        "        \"answer\": \"Final answer based on the reasoning.\"\n",
        "      }},\n",
        "      {{\n",
        "        \"question\": \"Another complex question?\",\n",
        "        \"reasoning\": \"Step 1: First, I'll analyze...\\nStep 2: Next, I need to determine...\\nStep 3: Based on this analysis...\",\n",
        "        \"answer\": \"Final answer drawn from the reasoning.\"\n",
        "      }}\n",
        "    ]\n",
        "\n",
        "    Text:\n",
        "    {text}\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "pathlib.Path(\"configs/config.yaml\").write_text(cfg)\n",
        "print(cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5-B5wNJK7Xn-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-B5wNJK7Xn-",
        "outputId": "714f8cec-937c-40fd-b186-99a50f9efc55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your OpenAI API key and hit Enter: ··········\n"
          ]
        }
      ],
      "source": [
        "import os, getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your OpenAI API key and hit Enter: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kopBrlwzlifC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kopBrlwzlifC",
        "outputId": "32e63e09-3d61-4e17-98dd-38de817601d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "\u001b[1;34mEnvironment variable check:\u001b[0m\n",
            "API_ENDPOINT_KEY: Not found\n",
            "get_llm_provider returning: api-endpoint\n",
            "API_ENDPOINT_KEY environment variable: Not found\n",
            "\u001b[2K\u001b[32m⠦\u001b[0m Checking API endpoint access...INFO:httpx:HTTP Request: GET https://api.openai.com/v1/models \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m API endpoint access confirmed\u001b[0m\n",
            "\u001b[2K\u001b[32mUsing custom API base: \u001b[0m\u001b[4;94mhttps://api.openai.com/v1\u001b[0m\n",
            "\u001b[2K\u001b[32mDefault model: gpt-4o-mini\u001b[0m\n",
            "\u001b[2K\u001b[32m⠧\u001b[0m Checking API endpoint access...\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ],
      "source": [
        "!synthetic-data-kit -c configs/config.yaml system-check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NF4vpnsi4af-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NF4vpnsi4af-",
        "outputId": "c764e2d9-916c-45d5-fcee-c0e321dd314a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-A20-010 Job Aid – How to Upload \n",
            "and Reference a Document in SharePoint (corporate documents)_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 16 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 18 QA pairs total\n",
            "Saving result to data/generated/GUI-A20-010 Job Aid – How to Upload and Reference a Document in SharePoint (corporate documents)_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-A20-010 Job Aid – How to Upload and Reference a Document in SharePoint (corporate documents)_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-A20-010 Job Aid – How to Upload and \n",
            "Reference a Document in SharePoint (corporate documents)_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-A20-010 Job Aid – How to Upload and \n",
            "Reference a Document in SharePoint (corporate \n",
            "documents)_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-A20-010 Job Aid – How \n",
            "to Upload and Reference a Document in SharePoint (corporate \n",
            "documents)_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-A20-100 Job Aid - SharePoint and\n",
            "Contractual Documents_EN_V1.1.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 2 QA pairs total\n",
            "Saving result to data/generated/GUI-A20-100 Job Aid - SharePoint and Contractual Documents_EN_V1.1_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-A20-100 Job Aid - SharePoint and Contractual Documents_EN_V1.1_qa_pairs.json\n",
            " Content saved to data/generated/GUI-A20-100 Job Aid - SharePoint and \n",
            "Contractual Documents_EN_V1.1_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 9.8\n",
            " Cleaned content saved to data/output/GUI-A20-100 Job Aid - SharePoint and \n",
            "Contractual Documents_EN_V1.1_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-A20-100 Job Aid - \n",
            "SharePoint and Contractual Documents_EN_V1.1_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-A61-100 Job Aid - Project Risk \n",
            "Analysis_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 14 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 21 QA pairs total\n",
            "Saving result to data/generated/GUI-A61-100 Job Aid - Project Risk Analysis_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-A61-100 Job Aid - Project Risk Analysis_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-A61-100 Job Aid - Project Risk \n",
            "Analysis_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 9.8\n",
            " Cleaned content saved to data/output/GUI-A61-100 Job Aid - Project Risk \n",
            "Analysis_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-A61-100 Job Aid - \n",
            "Project Risk Analysis_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-B31-100 Job Aid - Opening a \n",
            "Sales Project_EN_V1.1.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 20 QA pairs total\n",
            "Saving result to data/generated/GUI-B31-100 Job Aid - Opening a Sales Project_EN_V1.1_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-B31-100 Job Aid - Opening a Sales Project_EN_V1.1_qa_pairs.json\n",
            " Content saved to data/generated/GUI-B31-100 Job Aid - Opening a Sales \n",
            "Project_EN_V1.1_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-B31-100 Job Aid - Opening a Sales \n",
            "Project_EN_V1.1_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-B31-100 Job Aid - \n",
            "Opening a Sales Project_EN_V1.1_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-B31-110 Job Aid - Opening a \n",
            "Client Project in GP for Project Accounting_EN_V1.2.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 4 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 20 QA pairs total\n",
            "Saving result to data/generated/GUI-B31-110 Job Aid - Opening a Client Project in GP for Project Accounting_EN_V1.2_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-B31-110 Job Aid - Opening a Client Project in GP for Project Accounting_EN_V1.2_qa_pairs.json\n",
            " Content saved to data/generated/GUI-B31-110 Job Aid - Opening a Client Project \n",
            "in GP for Project Accounting_EN_V1.2_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-B31-110 Job Aid - Opening a Client \n",
            "Project in GP for Project Accounting_EN_V1.2_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-B31-110 Job Aid - \n",
            "Opening a Client Project in GP for Project Accounting_EN_V1.2_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-001 Job Aid - Create a \n",
            "Custom Dashboard_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 6 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 18 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-001 Job Aid - Create a Custom Dashboard_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-001 Job Aid - Create a Custom Dashboard_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-001 Job Aid - Create a Custom \n",
            "Dashboard_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-001 Job Aid - Create a Custom \n",
            "Dashboard_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-001 Job Aid - \n",
            "Create a Custom Dashboard_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-002 Job Aid - Create Custom \n",
            "Views_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 9 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 18 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-002 Job Aid - Create Custom Views_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-002 Job Aid - Create Custom Views_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-002 Job Aid - Create Custom \n",
            "Views_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-002 Job Aid - Create Custom \n",
            "Views_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-002 Job Aid - \n",
            "Create Custom Views_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-010 Job Aid - Quick Creation\n",
            "of a Client Account_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 6 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 17 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-010 Job Aid - Quick Creation of a Client Account_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-010 Job Aid - Quick Creation of a Client Account_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-010 Job Aid - Quick Creation of a \n",
            "Client Account_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-010 Job Aid - Quick Creation of a \n",
            "Client Account_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-010 Job Aid - \n",
            "Quick Creation of a Client Account_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-015 Job Aid - Create a Child\n",
            "Account_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 20 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-015 Job Aid - Create a Child Account_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-015 Job Aid - Create a Child Account_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-015 Job Aid - Create a Child \n",
            "Account_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-015 Job Aid - Create a Child \n",
            "Account_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-015 Job Aid - \n",
            "Create a Child Account_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-100 Job Aid - Potential \n",
            "Leads_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 0 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-100 Job Aid - Potential Leads_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-100 Job Aid - Potential Leads_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-100 Job Aid - Potential \n",
            "Leads_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Error: No QA pairs found in the input file\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-100 Job Aid - \n",
            "Potential Leads_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-110 Job Aid - Delegate the \n",
            "Entry of the Lead Qualification_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 19 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-110 Job Aid - Delegate the Entry of the Lead Qualification_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-110 Job Aid - Delegate the Entry of the Lead Qualification_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-110 Job Aid - Delegate the Entry of the\n",
            "Lead Qualification_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-110 Job Aid - Delegate the Entry \n",
            "of the Lead Qualification_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-110 Job Aid - \n",
            "Delegate the Entry of the Lead Qualification_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-120 Job Aid - Disqualify a \n",
            "Lead_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 19 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-120 Job Aid - Disqualify a Lead_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-120 Job Aid - Disqualify a Lead_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-120 Job Aid - Disqualify a \n",
            "Lead_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-120 Job Aid - Disqualify a \n",
            "Lead_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-120 Job Aid - \n",
            "Disqualify a Lead_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-200 Job Aid - Call Up \n",
            "Opportunity_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 3 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 21 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-200 Job Aid - Call Up Opportunity_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-200 Job Aid - Call Up Opportunity_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-200 Job Aid - Call Up \n",
            "Opportunity_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-200 Job Aid - Call Up \n",
            "Opportunity_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-200 Job Aid - Call\n",
            "Up Opportunity_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-210 Job Aid - Opportunity \n",
            "Master Agreement_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 3 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 21 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-210 Job Aid - Opportunity Master Agreement_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-210 Job Aid - Opportunity Master Agreement_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-210 Job Aid - Opportunity Master \n",
            "Agreement_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-210 Job Aid - Opportunity Master \n",
            "Agreement_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-210 Job Aid - \n",
            "Opportunity Master Agreement_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C20-215 Job Aid - Recreate \n",
            "MSA_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 19 QA pairs total\n",
            "Saving result to data/generated/GUI-C20-215 Job Aid - Recreate MSA_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C20-215 Job Aid - Recreate MSA_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C20-215 Job Aid - Recreate \n",
            "MSA_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C20-215 Job Aid - Recreate \n",
            "MSA_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C20-215 Job Aid - \n",
            "Recreate MSA_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C30-100 Job Aid - Using Project \n",
            "Ops and Finding the SharePoint_EN_V1.1.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 2 QA pairs total\n",
            "Saving result to data/generated/GUI-C30-100 Job Aid - Using Project Ops and Finding the SharePoint_EN_V1.1_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C30-100 Job Aid - Using Project Ops and Finding the SharePoint_EN_V1.1_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C30-100 Job Aid - Using Project Ops and \n",
            "Finding the SharePoint_EN_V1.1_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 9.8\n",
            " Cleaned content saved to data/output/GUI-C30-100 Job Aid - Using Project Ops \n",
            "and Finding the SharePoint_EN_V1.1_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C30-100 Job Aid - \n",
            "Using Project Ops and Finding the SharePoint_EN_V1.1_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C30-200 Job Aid - Client Project\n",
            "Structure Change Request (SDP - WBS)_EN_V1.1.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 1 QA pairs total\n",
            "Saving result to data/generated/GUI-C30-200 Job Aid - Client Project Structure Change Request (SDP - WBS)_EN_V1.1_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C30-200 Job Aid - Client Project Structure Change Request (SDP - WBS)_EN_V1.1_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C30-200 Job Aid - Client Project Structure \n",
            "Change Request (SDP - WBS)_EN_V1.1_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C30-200 Job Aid - Client Project \n",
            "Structure Change Request (SDP - WBS)_EN_V1.1_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C30-200 Job Aid - \n",
            "Client Project Structure Change Request (SDP - WBS)_EN_V1.1_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C30-210 Job Aid - SDP_WBS File \n",
            "Opening and Notification Process_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 19 QA pairs total\n",
            "Saving result to data/generated/GUI-C30-210 Job Aid - SDP_WBS File Opening and Notification Process_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C30-210 Job Aid - SDP_WBS File Opening and Notification Process_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C30-210 Job Aid - SDP_WBS File Opening and \n",
            "Notification Process_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 9.8\n",
            " Cleaned content saved to data/output/GUI-C30-210 Job Aid - SDP_WBS File Opening\n",
            "and Notification Process_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C30-210 Job Aid - \n",
            "SDP_WBS File Opening and Notification Process_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C30-220 Job Aid - Project \n",
            "Amendment Process_EN_V1.0 (1).txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 3 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 21 QA pairs total\n",
            "Saving result to data/generated/GUI-C30-220 Job Aid - Project Amendment Process_EN_V1.0 (1)_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C30-220 Job Aid - Project Amendment Process_EN_V1.0 (1)_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C30-220 Job Aid - Project Amendment \n",
            "Process_EN_V1.0 (1)_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 9.8\n",
            " Cleaned content saved to data/output/GUI-C30-220 Job Aid - Project Amendment \n",
            "Process_EN_V1.0 (1)_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C30-220 Job Aid - \n",
            "Project Amendment Process_EN_V1.0 (1)_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C30-220 Job Aid - Project \n",
            "Amendment Process_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 3 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 21 QA pairs total\n",
            "Saving result to data/generated/GUI-C30-220 Job Aid - Project Amendment Process_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C30-220 Job Aid - Project Amendment Process_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C30-220 Job Aid - Project Amendment \n",
            "Process_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C30-220 Job Aid - Project Amendment \n",
            "Process_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C30-220 Job Aid - \n",
            "Project Amendment Process_EN_V1.0_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Text successfully extracted to data/output/GUI-C31-110 Job Aid - Creation of a \n",
            "Client Project_EN_V1.0.txt\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "L Using api-endpoint provider\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 chunks to generate QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Generated 20 QA pairs total\n",
            "Saving result to data/generated/GUI-C31-110 Job Aid - Creation of a Client Project_EN_V1.0_qa_pairs.json\n",
            "Successfully wrote test file to data/generated/test_write.json\n",
            "Successfully wrote result to data/generated/GUI-C31-110 Job Aid - Creation of a Client Project_EN_V1.0_qa_pairs.json\n",
            " Content saved to data/generated/GUI-C31-110 Job Aid - Creation of a Client \n",
            "Project_EN_V1.0_qa_pairs.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "API_ENDPOINT_KEY from environment: Not found\n",
            "Using API key: None\n",
            "No API key found!\n",
            "Using API base URL: https://api.openai.com/v1\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Processing 1 batches of QA pairs...\n",
            "Processing batch 1/1...\r                                                                                \rBatch processing complete.\n",
            "Rated 5 QA pairs\n",
            "Retained 5 pairs (threshold: 7.5)\n",
            "Average score: 10.0\n",
            " Cleaned content saved to data/output/GUI-C31-110 Job Aid - Creation of a Client\n",
            "Project_EN_V1.0_qa_pairs_cleaned.json\n",
            "Loading config from: /usr/local/lib/python3.11/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: configs/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            " Converted to chatml format and saved to data/cleaned/GUI-C31-110 Job Aid - \n",
            "Creation of a Client Project_EN_V1.0_cleaned.json\n",
            "✅  done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "CONFIG=\"configs/config.yaml\"\n",
        "# mkdir -p data/output data/generated data/cleaned   # just in case\n",
        "\n",
        "for pdf in data/pdf/*.pdf; do\n",
        "  base=$(basename \"$pdf\" .pdf)\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" ingest \"$pdf\" \\\n",
        "                     --output-dir data/output\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" create \"data/output/${base}.txt\" \\\n",
        "                     --type qa -n 20 \\\n",
        "                     --output-dir data/generated\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" curate \\\n",
        "                     \"data/generated/${base}_qa_pairs.json\" \\\n",
        "                     --threshold 7.5\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" save-as \\\n",
        "                     \"data/generated/${base}_qa_pairs.json\" \\\n",
        "                     --format chatml \\\n",
        "                     --output \"data/cleaned/${base}_cleaned.json\"\n",
        "done\n",
        "echo \"✅  done\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jEHvDBVF7_Gz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "jEHvDBVF7_Gz",
        "outputId": "a688d1c0-e760-42df-ac33-109ba4b9bd10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            question  \\\n",
            "0  What is the purpose of the GUI-A20-010 Job Aid...   \n",
            "1  What steps should be taken to confirm if a doc...   \n",
            "2  How can a user narrow down search results when...   \n",
            "3  What steps can be taken to filter search resul...   \n",
            "4  How can you determine the location of a docume...   \n",
            "5  What is the procedure for uploading a document...   \n",
            "6  What is the primary location for uploading a c...   \n",
            "7  How should a bilingual or unilingual document ...   \n",
            "8  What should be done if a document is bilingual...   \n",
            "9  What steps should be taken to clean up duplica...   \n",
            "\n",
            "                                              answer  \n",
            "0  The purpose of the GUI-A20-010 Job Aid is to o...  \n",
            "1  To confirm if a document is already uploaded t...  \n",
            "2  A user can narrow down search results by using...  \n",
            "3  You can use the tabs to filter the search resu...  \n",
            "4  If you find multiple files, you can click or h...  \n",
            "5  To reduce the risk of obsolete documents, do n...  \n",
            "6  The primary location for uploading a controlle...  \n",
            "7  A bilingual or unilingual document should be u...  \n",
            "8  If a document is bilingual or unilingual, it s...  \n",
            "9  To clean up duplicate documents uploaded in mu...  \n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_828405e6-43a1-4f42-8bad-6bc752fbd269\", \"all_qa_pairs.xlsx\", 27366)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# folder that holds your ChatML JSON files\n",
        "SOURCE_DIR = \"data/cleaned\"          # change if different\n",
        "PATTERN    = f\"{SOURCE_DIR}/*.json\"  # leave as-is unless extension differs\n",
        "\n",
        "import json, glob, os, pandas as pd, pathlib\n",
        "from google.colab import files\n",
        "\n",
        "rows = []\n",
        "\n",
        "for path in sorted(glob.glob(PATTERN)):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        raw = f.read().strip()\n",
        "\n",
        "    # Some files might hold multiple JSON objects (ndjson)\n",
        "    try:\n",
        "        objs = [json.loads(raw)]\n",
        "    except json.JSONDecodeError:\n",
        "        objs = [json.loads(line) for line in raw.splitlines() if line.strip()]\n",
        "\n",
        "    for obj in objs:\n",
        "        msgs = obj.get(\"messages\", [])\n",
        "        user_q = None\n",
        "        for m in msgs:\n",
        "            role = m.get(\"role\")\n",
        "            content = m.get(\"content\", \"\").strip()\n",
        "            if role == \"user\":\n",
        "                user_q = content\n",
        "            elif role == \"assistant\" and user_q:\n",
        "                rows.append({\"question\": user_q, \"answer\": content})\n",
        "                break    # we only need the first Q-A pair\n",
        "\n",
        "# ▶ build DataFrame\n",
        "df = pd.DataFrame(rows, columns=[\"question\", \"answer\"])\n",
        "\n",
        "# ▶ save to Excel\n",
        "out_dir  = pathlib.Path(\"/content/result\"); out_dir.mkdir(exist_ok=True)\n",
        "out_path = out_dir / \"all_qa_pairs.xlsx\"\n",
        "df.to_excel(out_path, index=False)\n",
        "\n",
        "# ▶ quick preview + download link\n",
        "print(df.head(10))\n",
        "files.download(str(out_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ehJrjk5ASqhl",
      "metadata": {
        "id": "ehJrjk5ASqhl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "meta-llama-synthetic-data",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
