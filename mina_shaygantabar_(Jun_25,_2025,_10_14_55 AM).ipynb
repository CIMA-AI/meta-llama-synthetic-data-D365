{
  "cells": [
    {
      "cell_type": "code",
      "id": "p5xTQS8cvAyNmalodlQYI4G7",
      "metadata": {
        "tags": [],
        "id": "p5xTQS8cvAyNmalodlQYI4G7"
      },
      "source": [
        "!pip install -q gcsfs pyyaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/meta-llama/synthetic-data-kit.git@main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4TiLXJuiLjR",
        "outputId": "bde674ec-a183-45f2-ca28-4532f8c114ad",
        "collapsed": true
      },
      "id": "y4TiLXJuiLjR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/meta-llama/synthetic-data-kit.git@main\n",
            "  Cloning https://github.com/meta-llama/synthetic-data-kit.git (to revision main) to /tmp/pip-req-build-bl6wu2v7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/meta-llama/synthetic-data-kit.git /tmp/pip-req-build-bl6wu2v7\n",
            "  Resolved https://github.com/meta-llama/synthetic-data-kit.git to commit 2e68548299df4383f1c5b34f3a9883e8840f9ac6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bootstrap-flask>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (2.5.0)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (2.14.4)\n",
            "Requirement already satisfied: flask-wtf>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (1.2.2)\n",
            "Requirement already satisfied: flask>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (3.1.1)\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (1.84.0)\n",
            "Requirement already satisfied: pdfminer-six>=20221105 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (20250506)\n",
            "Requirement already satisfied: pydantic>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (2.11.5)\n",
            "Requirement already satisfied: python-docx>=0.8.11 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (1.2.0)\n",
            "Requirement already satisfied: python-pptx>=0.6.21 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (1.0.2)\n",
            "Requirement already satisfied: pytube>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (15.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (2.32.3)\n",
            "Requirement already satisfied: rich>=13.4.2 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (13.9.4)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from synthetic-data-kit==0.0.4b2) (0.16.0)\n",
            "Requirement already satisfied: WTForms in /usr/local/lib/python3.11/dist-packages (from bootstrap-flask>=2.2.0->synthetic-data-kit==0.0.4b2) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (24.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->synthetic-data-kit==0.0.4b2) (3.1.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->synthetic-data-kit==0.0.4b2) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->synthetic-data-kit==0.0.4b2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->synthetic-data-kit==0.0.4b2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->synthetic-data-kit==0.0.4b2) (0.4.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx>=0.8.11->synthetic-data-kit==0.0.4b2) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx>=0.6.21->synthetic-data-kit==0.0.4b2) (11.2.1)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx>=0.6.21->synthetic-data-kit==0.0.4b2) (3.2.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->synthetic-data-kit==0.0.4b2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->synthetic-data-kit==0.0.4b2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->synthetic-data-kit==0.0.4b2) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.4.2->synthetic-data-kit==0.0.4b2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.4.2->synthetic-data-kit==0.0.4b2) (2.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->synthetic-data-kit==0.0.4b2) (1.5.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (1.17.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.20.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->synthetic-data-kit==0.0.4b2) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->synthetic-data-kit==0.0.4b2) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->synthetic-data-kit==0.0.4b2) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (2025.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20221105->synthetic-data-kit==0.0.4b2) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.14.0->synthetic-data-kit==0.0.4b2) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import vertexai, os\n",
        "PROJECT_ID   = \"poc-uni-t-plus\"\n",
        "LOCATION     = \"us-central1\"\n",
        "BUCKET       = \"qa-benchmark\"\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "hdDygfhxciS0"
      },
      "id": "hdDygfhxciS0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data folder and configs\n",
        "!mkdir -p data/{pdf,html,youtube,docx,ppt,txt,output,generated,cleaned,final} configs"
      ],
      "metadata": {
        "id": "RH3oVTtQf0XP"
      },
      "id": "RH3oVTtQf0XP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer data from gcs to data folder here\n",
        "!gsutil -m cp gs://qa-benchmark/raw/*.pdf data/pdf/"
      ],
      "metadata": {
        "id": "KLta4wTYDQfI"
      },
      "id": "KLta4wTYDQfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Colab cell 4 ──\n",
        "import textwrap, yaml, pathlib, json, os\n",
        "\n",
        "cfg = textwrap.dedent(f\"\"\"\n",
        "# configs/openai.yaml  ── just the LLM section ──\n",
        "llm:\n",
        "  provider: \"api-endpoint\"          # <- tells the kit we’re using HTTPS, not vLLM\n",
        "\n",
        "api-endpoint:\n",
        "  api_base: \"https://api.openai.com/v1\"   # OpenAI REST root\n",
        "  api_key: \"\"\n",
        "  model:    \"gpt-4o-mini\"\n",
        "  max_retries: 3\n",
        "  retry_delay: 1.0\n",
        "\n",
        "generation:\n",
        "  temperature: 0.5   # Higher = more creative, lower = more deterministic\n",
        "  top_p: 0.95        # Nucleus sampling parameter\n",
        "  chunk_size: 500   # Size of text chunks for processing\n",
        "  overlap: 50       # Overlap between chunks to maintain context\n",
        "  max_tokens: 10000   # Maximum tokens in LLM responses\n",
        "  num_pairs: 30      # Default number of QA pairs to generate\n",
        "  num_cot_examples: 5  # Default number of Chain of Thought examples to generate\n",
        "  num_cot_enhance_examples: null  # Maximum number of conversations to enhance (null = enhance all)\n",
        "  batch_size: 32     # Number of requests to batch together (for create)\n",
        "\n",
        "# Content curation parameters\n",
        "curate:\n",
        "  threshold: 7.0     # Default quality threshold (1-10)\n",
        "  batch_size: 32     # Number of items per batch for rating\n",
        "  inference_batch: 32 # Number of batches to process at once with VLLM\n",
        "  temperature: 0.1   # Temperature for rating (lower = more consistent)\n",
        "\n",
        "# Format conversion parameters\n",
        "format:\n",
        "  default: \"jsonl\"   # Default output format\n",
        "  include_metadata: true  # Include metadata in output files\n",
        "  pretty_json: true  # Use indentation in JSON output\n",
        "\n",
        "# Prompts for different tasks\n",
        "prompts:\n",
        "  # Summary generation prompt\n",
        "  summary: |\n",
        "    Summarize the provided document in 3–5 sentences. Your summary should clearly identify the main topic, highlight the most important concepts or procedures, and capture any essential technical details or requirements. Avoid including minor details or tangential information. Write your summary in clear, concise language, ensuring that it provides an accurate overview for someone unfamiliar with the original document\n",
        "\n",
        "  # QA pair generation prompt\n",
        "  qa_generation: |\n",
        "    You are required to generate {num_pairs} complex and meaningful question-answer pairs from the provided document content to build a validation dataset. Follow these guidelines carefully: Please provide complete answers to the questions; do not give incomplete or partial answers. Each answer must provide all necessary details explicitly. Base your question on the technical aspects of the documents. Formulate realistic and meaningful questions that anticipate genuine inquiries a user might have regarding the technical procedures, rules, or detailed instructions described in the document. Avoid overly simplistic, trivial, or obvious questions. Ensure all questions directly address the technical aspects or detailed procedural content within the document. Do not create administrative or ownership-related\n",
        "\n",
        "    Rules:\n",
        "    1. Questions must be about important facts in the text\n",
        "    2. Answers must be directly supported by the text\n",
        "    3. Return JSON format only:\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"question\": \"Question 1?\",\n",
        "        \"answer\": \"Answer 1.\"\n",
        "      }},\n",
        "      {{\n",
        "        \"question\": \"Question 2?\",\n",
        "        \"answer\": \"Answer 2.\"\n",
        "      }}\n",
        "    ]\n",
        "\n",
        "    Text:\n",
        "    {text}\n",
        "  cot_generation: |\n",
        "    Create {num_examples} complex reasoning examples from this text that demonstrate chain-of-thought thinking.\n",
        "\n",
        "    Each example should have:\n",
        "    1. A challenging question that requires step-by-step reasoning\n",
        "    2. Detailed reasoning steps that break down the problem\n",
        "    3. A concise final answer\n",
        "\n",
        "    Return JSON format only:\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"question\": \"Complex question about the text?\",\n",
        "        \"reasoning\": \"Step 1: First, I need to consider...\\nStep 2: Then, I analyze...\\nStep 3: Finally, I can conclude...\",\n",
        "        \"answer\": \"Final answer based on the reasoning.\"\n",
        "      }},\n",
        "      {{\n",
        "        \"question\": \"Another complex question?\",\n",
        "        \"reasoning\": \"Step 1: First, I'll analyze...\\nStep 2: Next, I need to determine...\\nStep 3: Based on this analysis...\",\n",
        "        \"answer\": \"Final answer drawn from the reasoning.\"\n",
        "      }}\n",
        "    ]\n",
        "\n",
        "    Text:\n",
        "    {text}\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "pathlib.Path(\"configs/config.yaml\").write_text(cfg)\n",
        "print(cfg)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_M8ujjYPEWc6"
      },
      "id": "_M8ujjYPEWc6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your OpenAI API key and hit Enter: \")\n"
      ],
      "metadata": {
        "id": "5-B5wNJK7Xn-"
      },
      "id": "5-B5wNJK7Xn-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!synthetic-data-kit -c configs/config.yaml system-check"
      ],
      "metadata": {
        "id": "kopBrlwzlifC"
      },
      "id": "kopBrlwzlifC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Colab cell 5 ──\n",
        "!synthetic-data-kit -c configs/config.yaml ingest data/pdf/GUI-A20-010-Job-Aid.pdf\n",
        "\n",
        "# → writes parsed text to data/output/sample_report.txt\n"
      ],
      "metadata": {
        "id": "NE8W0iMPGpsq"
      },
      "id": "NE8W0iMPGpsq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Colab cell 6 ──\n",
        "!synthetic-data-kit -c configs/config.yaml create data/output/GUI-A20-010-Job-Aid.txt \\\n",
        "        --type qa -n 10\n",
        "# generates → data/generated/sample_report_qa_pairs.json"
      ],
      "metadata": {
        "id": "I_CTgJfcHFB8"
      },
      "id": "I_CTgJfcHFB8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Colab cell 7 ──\n",
        "!synthetic-data-kit -c configs/config.yaml curate \\\n",
        "        data/output/GUI-A20-010-Job-Aid_qa_pairs.json\n",
        "# keeps high-quality examples → data/cleaned/sample_report_cleaned.json\n"
      ],
      "metadata": {
        "id": "XK9O-RPHHclg"
      },
      "id": "XK9O-RPHHclg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "CONFIG=\"configs/config.yaml\"\n",
        "mkdir -p data/output data/generated data/cleaned   # just in case\n",
        "\n",
        "for pdf in data/pdf/*.pdf; do\n",
        "  base=$(basename \"$pdf\" .pdf)\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" ingest \"$pdf\" \\\n",
        "                     --output-dir data/output\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" create \"data/output/${base}.txt\" \\\n",
        "                     --type qa -n 20 \\\n",
        "                     --output-dir data/generated\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" curate \\\n",
        "                     \"data/generated/${base}_qa_pairs.json\" \\\n",
        "                     --threshold 7.5\n",
        "\n",
        "  synthetic-data-kit -c \"$CONFIG\" save-as \\\n",
        "                     \"data/generated/${base}_qa_pairs.json\" \\\n",
        "                     --format chatml \\\n",
        "                     --output \"data/cleaned/${base}_cleaned.json\"\n",
        "done\n",
        "echo \"✅  done\"\n"
      ],
      "metadata": {
        "id": "NF4vpnsi4af-"
      },
      "id": "NF4vpnsi4af-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SOURCE_DIR = \"data/generated\"          # folder that holds the 21 files\n",
        "PATTERN    = f\"{SOURCE_DIR}/*.json\"    # they all end with .json\n",
        "\n",
        "import json, glob, os, pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "rows = []\n",
        "\n",
        "for path in sorted(glob.glob(PATTERN)):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        doc = json.load(f)             # {\"summary\": \"...\", \"qa_pairs\": [...]}\n",
        "\n",
        "    qa_list = doc.get(\"qa_pairs\", [])\n",
        "    for pair in qa_list:\n",
        "        rows.append({\n",
        "            \"question\": pair.get(\"question\", \"\").strip(),\n",
        "            \"answer\"  : pair.get(\"answer\", \"\").strip(),\n",
        "            \"file\"    : os.path.basename(path)         # keep source file name\n",
        "        })\n",
        "\n",
        "# build the DataFrame (drop \"file\" if you don't need it)\n",
        "df = pd.DataFrame(rows, columns=[\"question\", \"answer\", \"file\"])\n",
        "\n",
        "# save everything to one Excel workbook\n",
        "out_path = \"/content/all_qa_pairs.xlsx\"\n",
        "df.to_excel(out_path, index=False)\n",
        "\n",
        "# show a quick preview in the notebook\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "id": "jEHvDBVF7_Gz"
      },
      "id": "jEHvDBVF7_Gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openpyxl"
      ],
      "metadata": {
        "id": "mf7ipGXRHa-R"
      },
      "id": "mf7ipGXRHa-R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/all_qa_pairs.xlsx\")\n"
      ],
      "metadata": {
        "id": "8Gfg9R2PSQfP"
      },
      "id": "8Gfg9R2PSQfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 – SET THIS to the folder that contains all your JSON files\n",
        "SOURCE_DIR = \"data/cleaned\"          # e.g. \"data/generated\" or \"data/output\"\n",
        "PATTERN    = f\"{SOURCE_DIR}/*.json\"    # tweak if your filenames differ\n",
        "\n",
        "import json, glob, os, pandas as pd, re\n",
        "from google.colab import files\n",
        "\n",
        "rows = []\n",
        "\n",
        "def add_pair(q, a):\n",
        "    \"\"\"Helper to append a clean Q-A row if both parts exist.\"\"\"\n",
        "    q, a = (q or \"\").strip(), (a or \"\").strip()\n",
        "    if q and a:\n",
        "        rows.append({\"question\": q, \"answer\": a})\n",
        "\n",
        "# ---------- read every JSON file ----------\n",
        "for path in sorted(glob.glob(PATTERN)):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        # Some files may contain many JSON objects, one per line\n",
        "        raw = f.read().strip()\n",
        "        if not raw:\n",
        "            continue\n",
        "\n",
        "    # try to load the whole file; if that fails assume NDJSON (one-per-line)\n",
        "    try:\n",
        "        objs = [json.loads(raw)]\n",
        "    except json.JSONDecodeError:\n",
        "        objs = [json.loads(line) for line in raw.splitlines() if line.strip()]\n",
        "\n",
        "    for obj in objs:\n",
        "        # -------- Structure A ------------------------------------------------\n",
        "        if isinstance(obj, dict) and \"qa_pairs\" in obj:\n",
        "            for qa in obj[\"qa_pairs\"]:\n",
        "                add_pair(qa.get(\"question\"), qa.get(\"answer\"))\n",
        "\n",
        "        # -------- Structure B ------------------------------------------------\n",
        "        elif isinstance(obj, dict) and \"messages\" in obj:\n",
        "            msgs = obj[\"messages\"]\n",
        "            pending_q = None\n",
        "            for m in msgs:\n",
        "                role = m.get(\"role\")\n",
        "                text = m.get(\"content\", \"\").strip()\n",
        "                if role == \"user\":\n",
        "                    pending_q = text\n",
        "                elif role == \"assistant\" and pending_q:\n",
        "                    add_pair(pending_q, text)\n",
        "                    pending_q = None\n",
        "\n",
        "        # -------- Unknown structure -----------------------------------------\n",
        "        else:\n",
        "            print(f\"⚠️ Skipped unrecognised format in {os.path.basename(path)}\")\n",
        "\n",
        "# ---------- build DataFrame & export ----------\n",
        "if not rows:\n",
        "    raise ValueError(\"No question-answer pairs found. Check SOURCE_DIR & patterns.\")\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"question\", \"answer\"])\n",
        "excel_path = \"/content/data/final/all_qa_pairs.xlsx\"\n",
        "df.to_excel(excel_path, index=False)\n",
        "\n",
        "# quick preview\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "id": "aUSFrmS7caN8"
      },
      "id": "aUSFrmS7caN8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_8Z2k6rjDvc"
      },
      "id": "I_8Z2k6rjDvc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "mina.shaygantabar (Jun 25, 2025, 10:14:55 AM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}